{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missouri East Cast Iron Model Phase 1\n",
    "This is the first script for the mandated cast iron model replacement. It is designed to modify the cast iron model points by taking in an input CSV and adding leak repairs & pipe observations that are within 10' from cast iron main to the master point feature class.\n",
    "\n",
    "After it is run, a manual process will be needed to move some points closer and, occasionally, to generate points that were unable to be joined with an existing leak repair or pipe observation point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure to run Cast Iron Model (Missouri East)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Editing\n",
    "This step needs to be accomplished after this script is run.  \n",
    "\n",
    "Edit the MoveCloser feature class. It will have a number of point features that are further than 10' away from the nearest main. You will want to move those points onto the nearest main. If the point is out in the middle of nowhere, you can just delete it. \n",
    "\n",
    "This is also an opportunity to clean up existing points and main segment issues since editing is already in progress. The existing points are named *CIModelPoints* and the existing cast iron main segments are called *CI_MainModelSegments*. \n",
    "\n",
    "#### Check the Error_UnfoundPoints feature class\n",
    "If this first script finds missing records from the input table then it will generate a new, empty, feature class called *Error_UnfoundPoints*. You will need to manually transfer any missing records to this feature class. The field names should match up with the input data's csv/excel file except spaces will be filled with a \"_\" symbol. \n",
    "\n",
    "Make sure to fill out the following fields: *Actual_Finish, Primary_Break_Cause, Cast_Iron_Evaluation, Replacement_Criteria_Met, Wall_Remaining*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Inputs\n",
    "This script has several inputs, which are the various data pieces that are entered into it in order for it to run. This section goes over those, calling out the variable names, so that they can be modified as needed.\n",
    "The variables *ws* and *ws_gdb* are the first variables called. Variable ws holds the location to a folder directory and stands for workspace. It is where all of the outputs will be written to as well as where the workspace geodatabase will need to be located at. The Variable *ws_gdb* calls upon the *ws* variable and then assigns a geodatabase name within that folder. If you wish to redirect the script to use data in a different directory and geodatabase, you have to change these variables.\n",
    "\n",
    "The *ws_gdb* geodatabase is expected to hold the \"master\" model data which is referenced in the variables *ci_masterpoints*. The point feature class this  variable refences MUST be set up with specific field names. That is because the input CSV that comes from the Maximo9 side contains certain field names. The field names of the CSV, when converted into a table, need to match what is in the *ci_masterpoints*. \n",
    "\n",
    "The *in_csv* variable contains the input location for the input csv. This is used to translate that csv into a arcGIS table in the *ws_gdb* geodatabase. *in_csv* can be changed each time the script is run with no specific requirements or issues. If there are extra fields within the csv, the script will ignore them.\n",
    "\n",
    "*LeakRepairMaximo* and *PipeOb* are variables that refences feature services. This is because the Notebook Server can not reference SDE connection paths nor UNC folder paths easily. These should not be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Script\n",
    "These cells contain the scripting cells in Python for conducting the mandated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and Setup Functions\n",
    "The first step of the script is to import needed modules and set up any functions needed for the script. This script uses one function, *cleanMe*, to help clean up data prior to doing an append. This section of code should not need to be modified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import arcpy, os, datetime\n",
    "\n",
    "def cleanMe(layer, fldname, fld_list, del_field):\n",
    "    \"\"\" Cleans a layer after a join\n",
    "    Input requires an input feature class or table, the name of that table,\n",
    "    a list of fields to be deleted, and the join-name to identify fields to delete.\n",
    "    \n",
    "    This function works to clean up a join to delete every field that had been\n",
    "    joined. The joins it is intended to work on do not need fields from the join\n",
    "    but rather just location data and are attaching a table to a feature class.\n",
    "    \"\"\"\n",
    "    # Rename the deletion list based on the input field name\n",
    "    # deleting easier for fields that may have a duplicate after renaming like OBJECTID\n",
    "    del_list = [(fldname + \"_\" + item) for item in fld_list]\n",
    "    # Iterate through all fields in leak repair list that have the CI csv table name\n",
    "    # in the field name.\n",
    "    for field in arcpy.ListFields(layer):\n",
    "        if not field.required:\n",
    "            # Identify if the field name is in the deletion list\n",
    "            if field.name in del_list:\n",
    "                #...if it is, delete it\n",
    "                arcpy.management.DeleteField(layer, field.name)\n",
    "                #Else if the field name has MXSPAT_LeakRepair\n",
    "            elif del_field in field.name:\n",
    "                # delete the field\n",
    "                arcpy.management.DeleteField(layer, field.name)\n",
    "            # Else, alter fields\n",
    "            else: \n",
    "                # ...then get a new name removing the name of the CI csv table\n",
    "                newName = str(field.name.replace(fldname + \"_\", \"\"))    \n",
    "                #.....and change the name\n",
    "                arcpy.management.AlterField(layer, field.name, newName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Settings and Workspace Variables\n",
    "Next, set up environment settings and variable names. When you want to utilize a new workspace for the model, you can change the variables *ws* and *ws_gdb* to the name of the folder and the geodatabase respectively. *CastIronMainSegments* defines the name used for the cast iron main segments created previously while *ci_masterpoints* points to the point feature class containing all current cast-iron model points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment settings\n",
    "arcpy.env.overwriteOutput=True\n",
    "# Set feature class workspace\n",
    "ws = '/arcgis/directories/'\n",
    "# Set gdb workspace\n",
    "ws_gdb = os.path.join(ws, \"data.gdb\")\n",
    "# Set layer variables\n",
    "# Master cast iron point layer (updated in this script)\n",
    "ci_masterpoints = os.path.join(ws_gdb, \"CIModelPoints\")\n",
    "# set variables using the feature services\n",
    "LeakRepairMaximo = \"Portal REST Service\"\n",
    "PipeOb = \"Portal REST Service\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert CSV into GDB Table\n",
    "Below is code to convert the input csv table into an arcGIS table inside the workspace geodatabase. The variable *in_csv* can be changed to point to the input data each time the script is run. The cell below will also output a print of how many rows are in the created table. Verify that the table was created properly by checking that count against the number of rows in your input data. The counts should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CSV to a table\n",
    "in_csv = 'location/file.csv'\n",
    "ciTable_name = \"CIModel\"\n",
    "ci_table = arcpy.conversion.TableToTable(in_csv, ws_gdb, ciTable_name)\n",
    "# Get count of all rows in the imported CSV. Check this against the excel document\n",
    "# to verify they are the same\n",
    "csv_count = int(arcpy.management.GetCount(ci_table).getOutput(0))\n",
    "print(\"The imported table named {0} has a total of {1} rows.\".format(ciTable_name, csv_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Leak Repairs\n",
    "Run the below cell to create the *new_lr* feature class which will contain only the leak repairs identified in the input csv. It will output a statement letting you know where the new leak repairs were generated and how many were found. This will likely be slightly smaller than the count from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CI table work orders into a text field\n",
    "wo_txtfld = \"MXWONUM\"\n",
    "arcpy.AddField_management(ci_table, wo_txtfld, 'TEXT')\n",
    "arcpy.CalculateField_management(ci_table, wo_txtfld, '!Work_Order_ID!', 'PYTHON')\n",
    "#Create table view and feature layer to allow join\n",
    "ci_view = arcpy.MakeTableView_management (ci_table, ciTable_name)\n",
    "lr_lyr = arcpy.MakeFeatureLayer_management(LeakRepairMaximo, \"LRMaximo_Lyr\")\n",
    "# Add join using the work order id field\n",
    "arcpy.AddJoin_management (lr_lyr, wo_txtfld, ci_view, wo_txtfld, 'KEEP_COMMON')\n",
    "# Set path for new leak repairs\n",
    "new_lr_name = \"newLeakRepairs\"\n",
    "new_lr = os.path.join(ws_gdb, new_lr_name)\n",
    "# Copy those leak repairs to feature class\n",
    "arcpy.CopyFeatures_management (lr_lyr, new_lr)\n",
    "lr_count = int(arcpy.management.GetCount(new_lr).getOutput(0))\n",
    "print(\"Copied new leak repairs to {0}. A total of {1} leak repairs were found.\".format(new_lr, lr_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Duplicates\n",
    "After the new leak repair feature class is generated, we need to check for duplicate records. Sometimes there are leak repairs that have been updated. This is done by checking the location of new leak repairs to the master model feature class. The below code will output a count of the number of duplicates found that had to be removed. It will also create a copy of the master points named in the *date_master* variable. This copy contains the data prior to anything being deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up the field names of layers in the joined leak repair list\n",
    "# Create list of field names to delete from data after cleaning it\n",
    "del_list = ['OBJECTID', 'Work_Order_ID', 'GLOBALID']\n",
    "join_fc_name = \"L1Leak_Repair\"\n",
    "cleanMe(new_lr, ciTable_name, del_list, join_fc_name)\n",
    "# Remove the join\n",
    "arcpy.RemoveJoin_management (lr_lyr)\n",
    "# Create view layer of master ci points data \n",
    "master_lyr = arcpy.MakeFeatureLayer_management (ci_masterpoints, 'CIModelPointsLyr')\n",
    "# Create feature layer of leak repairs that exist in the model\n",
    "newlr_lyr = arcpy.MakeFeatureLayer_management (new_lr, new_lr_name)\n",
    "# Prior to selection and deletion, copy of master layer with date for later use or deletion\n",
    "date = str(datetime.datetime.now().date()).replace(\"-\", \"_\")\n",
    "date_master = \"CIModelPoints\" + \"_\" + date\n",
    "arcpy.CopyFeatures_management(master_lyr, os.path.join(ws_gdb, date_master))\n",
    "\n",
    "# Select existing cast iron lr points that match the leak repairs that exist in the model\n",
    "arcpy.SelectLayerByLocation_management (master_lyr, 'ARE_IDENTICAL_TO',newlr_lyr)\n",
    "dupe_count = int(arcpy.management.GetCount(master_lyr).getOutput(0))\n",
    "# Delete features in Ci Model points layer that match those found in the previous selection\n",
    "# this is done to clean up previously existing leak repairs that may have an update to their data\n",
    "arcpy.DeleteFeatures_management(master_lyr)\n",
    "print(\"Deleting {0} features from the master model points that were found to be duplicates. These are likely records that have updates to be applied.\".format(dupe_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Leak Repairs within 10'\n",
    "The below cell appends leak repairs that are within 10' of cast iron main to the master point feature class. It will print out a count of how many records were found within 10'. Afterwards, the code will generate the *move_lr* feature class with points that were further than 10'. It will give you a count of how many of those were found. \n",
    "\n",
    "The string in *move_lr* can be changed to change the name of the output feature class in the workspace gdb created previously (*ws_gdb*). \n",
    "\n",
    "These found points will be the ones to be moved manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast iron main segements (Created in script 2)\n",
    "CastIronMainSegments = os.path.join(ws_gdb, \"CI_MainModelSegments\")\n",
    "# Create feature layer for cast iron main segments\n",
    "ci_main_lyr = arcpy.MakeFeatureLayer_management (CastIronMainSegments, \n",
    "                                                 'CastIronMainSegmentsLyr')\n",
    "# Find new/updated leak repairs within 10' of cast iron \n",
    "arcpy.SelectLayerByLocation_management (newlr_lyr, 'WITHIN_A_DISTANCE',ci_main_lyr, \n",
    "                                        '10 FEET')\n",
    "lrTenFt_count = int(arcpy.management.GetCount(newlr_lyr).getOutput(0))\n",
    "# Append the leak repairs that are within 10' of cast iron main to the master point list\n",
    "arcpy.Append_management(newlr_lyr, master_lyr,\"NO_TEST\")\n",
    "print(\"A total of {0} records were found that are within 10' of a cast iron main.\".format(lrTenFt_count))\n",
    "# Select Leak repair layer and swap the selection to find points further than 10' away\n",
    "arcpy.SelectLayerByAttribute_management(newlr_lyr,\"SWITCH_SELECTION\",\"#\")\n",
    "closer_count = int(arcpy.management.GetCount(newlr_lyr).getOutput(0))\n",
    "# Create a feature class of points that need to be manually moved onto cast iron pipe\n",
    "move_lr = os.path.join(ws_gdb, \"MoveCloser\")\n",
    "arcpy.management.CopyFeatures(newlr_lyr, move_lr)\n",
    "print(\"A total of {0} records were found that are further than 10' of a cast iron main and will need to be manually moved closer.\".format(closer_count))\n",
    "#Clean up feature layers\n",
    "for item in [newlr_lyr, ci_main_lyr]:\n",
    "    arcpy.management.Delete(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Counts\n",
    "Run the below to check record counts. This is to verify that everything adds up appropriately and no leak repairs are being missed. If the count is off, the code segment will output an error and will generate a new feature class named in the *error_fc* variable. To change the name of the created, blank, feature class, change the string assigned to that variable. \n",
    "\n",
    "The empty feature class can be used to add the missed records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Leak Repair Counts\n",
    "print(\"Checking leak repair counts...\")\n",
    "print(\"Total new records (Leak Repairs and Pipe Observations) in input table: {0}.\".format(csv_count))\n",
    "print(\"Total number of new Leak Repairs identified: {0}.\".format(lr_count))\n",
    "print(\"New Leak Repairs 10' to cast iron main that have been appended: {0}\".format(lrTenFt_count))\n",
    "print(\"New Leak Repairs further than 10' from cast iron main: {0}.\".format(closer_count))\n",
    "if (closer_count + lrTenFt_count) == lr_count:\n",
    "    print(\"The counts for new leak repairs within 10' and further than 10' match the number of new leak repairs found.\")\n",
    "else: \n",
    "    print(\"The count for the new leak repairs is off. There are some records not being counted as within 10' or further than 10'. Check the data for problems.\")\n",
    "    error_fc = \"Error_UnfoundPoints\"\n",
    "    arcpy.management.CreateFeatureclass(ws_gdb, error_fc, \"POINT\", ci_view)\n",
    "    print(\"An empty feature class named {0} has been created. Please move records that did not get added in the above steps to this feature class.\".format(error_fc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify new pipe observations\n",
    "The below cell is used to identify pipe observations and create a table of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Identify new pipe observations##\n",
    "# Join leak repair layer to new CI table\n",
    "arcpy.AddJoin_management (ci_view, 'MXWONUM',lr_lyr, 'MXWONUM', 'KEEP_ALL')\n",
    "# sql query needed to identify null data\n",
    "query=r\"L1Leak_Repair.OBJECTID IS null\"\n",
    "# Select new records that aren't in leak repair data and are thus pipe observations\n",
    "arcpy.SelectLayerByAttribute_management(ci_view,\"\",query)\n",
    "# Clean up join to verify field names aren't crazy\n",
    "arcpy.RemoveJoin_management (ci_view)\n",
    "# Copy your new pipe obs records to table\n",
    "# Can probably create this \"memory\\\"\n",
    "new_pipeobs_name = \"PipeObsTbl\"\n",
    "new_obs = os.path.join(ws_gdb, new_pipeobs_name)\n",
    "#new_obs = os.path.join(ws_gdb, r\"memory\\\" + new_pipeobs_name)\n",
    "arcpy.CopyRows_management (ci_view, new_obs)\n",
    "# Count new observations\n",
    "newpo_count = int(arcpy.management.GetCount(new_obs).getOutput(0))\n",
    "# Clean up view and feature layers\n",
    "for item in [ci_view, lr_lyr]:\n",
    "    arcpy.management.Delete(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Pipe Observation Counts\n",
    "Check counts to see if the total of new pipe observations and leak repairs added matches the count from the input csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Pipe observation counts\n",
    "print(\"A total of {0} new pipe observations were found.\".format(newpo_count))\n",
    "if newpo_count + lr_count == csv_count:\n",
    "    print(\"The total of pipe observations({0}) and leak repairs ({1}) equals the total records found in new input table ({2}).\"\n",
    "          .format(newpo_count, lr_count, csv_count))\n",
    "else: \n",
    "    print(\"The total of pipe observations({0}) and leak repairs ({1}) does not match the total records found in new input table ({2}). Check the data to identify problems.\"\n",
    "          .format(newpo_count, lr_count, csv_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & Append New Pipe Observations\n",
    "This section creates the new pipe observations as *pipeObsNewLR*, cleans the fields up using the *cleanMe* function and then appends them to the master data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Adding new pipe observations to existing##\n",
    "arcpy.env.qualifiedFieldNames = False\n",
    "# Create view table of newly found pipe observations\n",
    "obs_lyr = arcpy.MakeTableView_management (new_obs, new_pipeobs_name)\n",
    "# Create feature layer of existing pipe observations from maximo\n",
    "pipe_name = 'Maximo_PipeObservations'\n",
    "pipe_lyr = arcpy.MakeFeatureLayer_management (PipeOb, pipe_name)\n",
    "# Join newly created table from cast iron model to all pipe observations\n",
    "# second join...not sure if it would work with selection + first join from above if avoiding creating new table\n",
    "arcpy.AddJoin_management (pipe_lyr, 'WORKORDERMX', obs_lyr, wo_txtfld, 'KEEP_COMMON')\n",
    "# querty for no nulls\n",
    "query= \"NOT \" + new_pipeobs_name + \".OBJECTID IS null\"\n",
    "# Identify where pipeOb table is found\n",
    "arcpy.SelectLayerByAttribute_management (pipe_name, '', query)\n",
    "# Copy just id'd pipe obs to FC\n",
    "pipeObsNewLR = os.path.join(ws_gdb, \"pipeObsNewLR\")\n",
    "arcpy.CopyFeatures_management (pipe_lyr, pipeObsNewLR)\n",
    "# Cleaning up new pipe observations\n",
    "cleanMe(pipeObsNewLR, new_pipeobs_name, del_list, join_fc_name)\n",
    "# Append new pipe obervations to master points\n",
    "arcpy.Append_management(pipeObsNewLR, master_lyr, \"NO_TEST\")\n",
    "# Clean up view tables and feature layers and intermediary feature classes/tables\n",
    "for item in [pipe_lyr, obs_lyr, master_lyr, new_obs, pipeObsNewLR, new_lr]:\n",
    "    arcpy.management.Delete(item)\n",
    "# Instead of deleting ci_table and new_lr, change its name to have current date stapled on.\n",
    "# It is kept due to possible errors in field names next time model is run.\n",
    "# Set new table name\n",
    "date_citable = ciTable_name + \"_\" + date\n",
    "# Check if table exists prior to rename. If it does, delete. only an issue if the script is run multiple times in the same day\n",
    "if arcpy.Exists(os.path.join(ws_gdb, date_citable)):\n",
    "    arcpy.Delete_management(os.path.join(ws_gdb, date_citable))  \n",
    "# Rename the feature class\n",
    "arcpy.management.Rename(ci_table, date_citable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Advanced",
   "notebookRuntimeVersion": "6.0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
